{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\greenblue\\Work\\study\\machineLearning\\DeepLearningZeroToAll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "하위 디렉터리 또는 파일 .\\logs이(가) 이미 있습니다.\n",
      "하위 디렉터리 또는 파일 .\\logs\\lab-10-1-mnist_softmax-tf2이(가) 이미 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "!echo %CD%\n",
    "!mkdir .\\logs\n",
    "!mkdir .\\logs\\lab-10-1-mnist_softmax-tf2\n",
    "!rmdir /q /s .\\logs\\lab-10-1-mnist_softmax-tf2\n",
    "\n",
    "log_dir = \"./logs/lab-10-1-mnist_softmax-tf2/\"\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = log_dir + current_time + '/train'\n",
    "test_log_dir = log_dir + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Cost: 5.098366261\n",
      "Epoch: 0002, Cost: 1.733558655\n",
      "Epoch: 0003, Cost: 1.122886419\n",
      "Epoch: 0004, Cost: 0.883196890\n",
      "Epoch: 0005, Cost: 0.752380669\n",
      "Epoch: 0006, Cost: 0.667544544\n",
      "Epoch: 0007, Cost: 0.606975436\n",
      "Epoch: 0008, Cost: 0.561246276\n",
      "Epoch: 0009, Cost: 0.525423467\n",
      "Epoch: 0010, Cost: 0.496609509\n",
      "Epoch: 0011, Cost: 0.472936690\n",
      "Epoch: 0012, Cost: 0.453118533\n",
      "Epoch: 0013, Cost: 0.436250567\n",
      "Epoch: 0014, Cost: 0.421689808\n",
      "Epoch: 0015, Cost: 0.408969969\n",
      "Epoch: 0016, Cost: 0.397745490\n",
      "Epoch: 0017, Cost: 0.387755930\n",
      "Epoch: 0018, Cost: 0.378798038\n",
      "Epoch: 0019, Cost: 0.370713025\n",
      "Epoch: 0020, Cost: 0.363370955\n",
      "Epoch: 0021, Cost: 0.356669098\n",
      "Epoch: 0022, Cost: 0.350520879\n",
      "Epoch: 0023, Cost: 0.344856530\n",
      "Epoch: 0024, Cost: 0.339617461\n",
      "Epoch: 0025, Cost: 0.334755450\n",
      "Epoch: 0026, Cost: 0.330229223\n",
      "Epoch: 0027, Cost: 0.326003969\n",
      "Epoch: 0028, Cost: 0.322049588\n",
      "Epoch: 0029, Cost: 0.318340182\n",
      "Epoch: 0030, Cost: 0.314853013\n",
      "Epoch: 0031, Cost: 0.311568558\n",
      "Epoch: 0032, Cost: 0.308469355\n",
      "Epoch: 0033, Cost: 0.305539578\n",
      "Epoch: 0034, Cost: 0.302765757\n",
      "Epoch: 0035, Cost: 0.300135136\n",
      "Epoch: 0036, Cost: 0.297637224\n",
      "Epoch: 0037, Cost: 0.295262039\n",
      "Epoch: 0038, Cost: 0.293000221\n",
      "Epoch: 0039, Cost: 0.290843546\n",
      "Epoch: 0040, Cost: 0.288785249\n",
      "Epoch: 0041, Cost: 0.286818624\n",
      "Epoch: 0042, Cost: 0.284937233\n",
      "Epoch: 0043, Cost: 0.283135980\n",
      "Epoch: 0044, Cost: 0.281409740\n",
      "Epoch: 0045, Cost: 0.279753953\n",
      "Epoch: 0046, Cost: 0.278163999\n",
      "Epoch: 0047, Cost: 0.276636690\n",
      "Epoch: 0048, Cost: 0.275168419\n",
      "Epoch: 0049, Cost: 0.273755223\n",
      "Epoch: 0050, Cost: 0.272394776\n",
      "Learning finished\n",
      "Accuracy:  0.9189\n",
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch: 0001 Cost: 5.745170949\\nEpoch: 0002 Cost: 1.780056722\\nEpoch: 0003 Cost: 1.122778654\\n...\\nEpoch: 0048 Cost: 0.271918680\\nEpoch: 0049 Cost: 0.270640434\\nEpoch: 0050 Cost: 0.269054370\\nLearning Finished!\\nAccuracy: 0.9194\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial as bind\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.find('2') == 0)\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = tf.reshape(x_train, [-1, 28*28])\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "y_train = tf.one_hot(y_train, 10)\n",
    "y_train = tf.cast(y_train, tf.float32)\n",
    "x_train_len = len(x_train)\n",
    "y_train_len = len(y_train)\n",
    "# print(x_train_len, y_train_len)\n",
    "# print(x_train, y_train)\n",
    "\n",
    "x_test = tf.reshape(x_test, [-1, 28*28])\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "y_test = tf.one_hot(y_test, 10)\n",
    "x_test_len = len(x_test)\n",
    "y_test_len = len(y_test)\n",
    "# print(x_test_len, y_test_len)\n",
    "# print(x_test, y_test)\n",
    "\n",
    "learning_rate = 0.001\n",
    "nb_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "num_iterations = int(x_train_len / batch_size)\n",
    "\n",
    "# weights & bias\n",
    "W = tf.Variable(tf.random.normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random.normal([nb_classes]))\n",
    "\n",
    "# define optimizer, cost/loss and others\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def hypothesis(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "@tf.function\n",
    "def cost(X, Y):\n",
    "    return tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis(X),\n",
    "                                                labels=tf.stop_gradient([Y]))\n",
    "    )\n",
    "\n",
    "@tf.function\n",
    "def correct_prediction(X, Y):\n",
    "    return tf.equal(tf.argmax(hypothesis(X), axis=1), tf.argmax(Y, axis=1))\n",
    "\n",
    "@tf.function\n",
    "def accuracy(X, Y):\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction(X, Y), tf.float32))\n",
    "\n",
    "# train my model\n",
    "for epoch in range(num_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        pos = i * batch_size\n",
    "        batch_xs = x_train[pos: pos + batch_size, :]\n",
    "        batch_ys = y_train[pos: pos + batch_size, :]\n",
    "#         print(batch_xs)\n",
    "#         print(batch_ys)\n",
    "        \n",
    "        cost_val = cost(batch_xs, batch_ys)\n",
    "        avg_cost += cost_val / num_iterations\n",
    "\n",
    "        # Minimize\n",
    "        optimizer.minimize(bind(cost, batch_xs, batch_ys), var_list=[W, b])\n",
    "\n",
    "        step = epoch * num_iterations + i\n",
    "        if step % 100 == 0:\n",
    "            with train_summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', cost_val, step=step)\n",
    "                tf.summary.scalar('accuracy', accuracy(batch_xs, batch_ys), step=step)\n",
    "        \n",
    "    tf.print(\"Epoch: {:04d}, Cost: {:.9f}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "tf.print(\"Learning finished\")\n",
    "\n",
    "# Test model and check accuracy\n",
    "tf.print(\n",
    "    \"Accuracy: \",\n",
    "    accuracy(x_test, y_test)\n",
    ")\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, y_test_len - 1)\n",
    "tf.print(\n",
    "    \"Label: \", tf.argmax(y_test[r : r + 1], 1)\n",
    ")\n",
    "tf.print(\n",
    "    \"Prediction: \",\n",
    "    tf.argmax(hypothesis(x_test[r : r + 1]), 1),\n",
    ")\n",
    "\n",
    "plt.imshow(\n",
    "    tf.reshape(x_test[r : r + 1], [28, 28]),\n",
    "    cmap=\"Greys\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Epoch: 0001 Cost: 5.745170949\n",
    "Epoch: 0002 Cost: 1.780056722\n",
    "Epoch: 0003 Cost: 1.122778654\n",
    "...\n",
    "Epoch: 0048 Cost: 0.271918680\n",
    "Epoch: 0049 Cost: 0.270640434\n",
    "Epoch: 0050 Cost: 0.269054370\n",
    "Learning Finished!\n",
    "Accuracy: 0.9194\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23120), started 0:01:05 ago. (Use '!kill 23120' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9ae2008e368f2fce\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9ae2008e368f2fce\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!taskkill /im tensorboard.exe /F\n",
    "%tensorboard --logdir logs --host \"0.0.0.0\" --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
