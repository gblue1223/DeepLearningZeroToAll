{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Cost:  1.00026965 W1:  [[0.769250154 0.374444366]\n",
      " [-0.0572497398 0.00466440339]] W2:  [[0.342847496]\n",
      " [-0.27289167]]\n",
      "Step:  1000 Cost:  0.692992806 W1:  [[0.762233317 0.359150946]\n",
      " [-0.157351404 -0.0394807905]] W2:  [[0.159113258]\n",
      " [-0.894644916]]\n",
      "Step:  2000 Cost:  0.691419303 W1:  [[0.843791068 0.352440089]\n",
      " [-0.407388657 -0.110210285]] W2:  [[0.415643424]\n",
      " [-0.910509]]\n",
      "Step:  3000 Cost:  0.674850702 W1:  [[1.30598426 0.514326334]\n",
      " [-1.18251443 -0.279946178]] W2:  [[1.14395452]\n",
      " [-1.01717]]\n",
      "Step:  4000 Cost:  0.481652 W1:  [[3.03450227 1.78813159]\n",
      " [-3.22811723 -1.48271179]] W2:  [[3.36035252]\n",
      " [-2.14074]]\n",
      "Step:  5000 Cost:  0.14689064 W1:  [[4.52585649 3.98780537]\n",
      " [-4.68320751 -3.68462396]] W2:  [[5.8824892]\n",
      " [-5.05218458]]\n",
      "Step:  6000 Cost:  0.0665281937 W1:  [[5.12835503 4.8693862]\n",
      " [-5.27853394 -4.57884169]] W2:  [[7.28003883]\n",
      " [-6.63635]]\n",
      "Step:  7000 Cost:  0.0411699563 W1:  [[5.4502306 5.31445456]\n",
      " [-5.60540485 -5.02964783]] W2:  [[8.1377573]\n",
      " [-7.55603647]]\n",
      "Step:  8000 Cost:  0.0294201 W1:  [[5.66209 5.59814072]\n",
      " [-5.82303858 -5.31674862]] W2:  [[8.74516]\n",
      " [-8.19145203]]\n",
      "Step:  9000 Cost:  0.0227592029 W1:  [[5.81759501 5.80209208]\n",
      " [-5.98366642 -5.52300072]] W2:  [[9.21270084]\n",
      " [-8.67422104]]\n",
      "Step:  10000 Cost:  0.0185030513 W1:  [[5.93939543 5.95949888]\n",
      " [-6.10985613 -5.68207407]] W2:  [[9.59179592]\n",
      " [-9.06259632]]\n",
      "\n",
      "Hypothesis:  [[0.0179311633]\n",
      " [0.975725889]\n",
      " [0.984022617]\n",
      " [0.0151228309]] \n",
      "Predicted:  [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]] \n",
      "Accuracy:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHypothesis:\\n[[0.01338216]\\n [0.98166394]\\n [0.98809403]\\n [0.01135799]] \\nPredicted:\\n[[0.]\\n [1.]\\n [1.]\\n [0.]] \\nAccuracy:\\n1.0\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lab 9 XOR\n",
    "from functools import partial as bind\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.find('2') == 0)\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random.normal([2]), name='bias1')\n",
    "layer1 = lambda X: tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random.normal([1]), name='bias2')\n",
    "hypothesis = lambda X: tf.sigmoid(tf.matmul(layer1(X), W2) + b2)\n",
    "\n",
    "# cost/loss function\n",
    "@tf.function\n",
    "def cost(X, Y):\n",
    "    return -tf.reduce_mean(\n",
    "        Y * tf.math.log(hypothesis(X)) + (1 - Y) * tf.math.log(1 - hypothesis(X))\n",
    "    )\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = lambda X: tf.cast(hypothesis(X) > 0.5, dtype=tf.float32)\n",
    "accuracy = lambda X, Y: tf.reduce_mean(tf.cast(tf.equal(predicted(X), Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "for step in range(10001):\n",
    "    optimizer.minimize(\n",
    "        bind(cost, x_data, y_data),\n",
    "        var_list=[W1, b1, W2, b2]\n",
    "    )\n",
    "    cost_val = cost(x_data, y_data)\n",
    "    if step % 1000 == 0:\n",
    "        tf.print(\"Step: \", step, \"Cost: \", cost_val, \"W1: \", W1, \"W2: \", W2)\n",
    "        \n",
    "# Accuracy report\n",
    "h, p, a = hypothesis(x_data), predicted(x_data), accuracy(x_data, y_data)\n",
    "tf.print(\"\\nHypothesis: \", h, \"\\nPredicted: \", p, \"\\nAccuracy: \", a)\n",
    "\n",
    "'''\n",
    "Hypothesis:\n",
    "[[0.01338216]\n",
    " [0.98166394]\n",
    " [0.98809403]\n",
    " [0.01135799]] \n",
    "Predicted:\n",
    "[[0.]\n",
    " [1.]\n",
    " [1.]\n",
    " [0.]] \n",
    "Accuracy:\n",
    "1.0\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
