{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  10843.3506 \n",
      "Prediction:\n",
      " [52.3568916 78.3032532 68.9596405 76.370575 62.863102]\n",
      "10 Cost:  21.0462303 \n",
      "Prediction:\n",
      " [144.40155 188.900513 177.950485 195.056656 147.214432]\n",
      "1990 Cost:  7.36382055 \n",
      "Prediction:\n",
      " [147.408417 187.370529 179.122284 195.98381 145.05719]\n",
      "2000 Cost:  7.32565308 \n",
      "Prediction:\n",
      " [147.418823 187.363419 179.125519 195.985931 145.048019]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n0 Cost:  19614.8\\nPrediction:\\n [ 21.69748688  39.10213089  31.82624626  35.14236832  32.55316544]\\n10 Cost:  14.0682\\nPrediction:\\n [ 145.56100464  187.94958496  178.50236511  194.86721802  146.08096313]\\n\\n ...\\n\\n1990 Cost:  4.9197\\nPrediction:\\n [ 148.15084839  186.88632202  179.6293335   195.81796265  144.46044922]\\n2000 Cost:  4.89449\\nPrediction:\\n [ 148.15931702  186.8805542   179.63194275  195.81971741  144.45298767]\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lab 4 Multi-variable linear regression\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.find('2') == 0)\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.Variable(x1_data)\n",
    "x2 = tf.Variable(x2_data)\n",
    "x3 = tf.Variable(x3_data)\n",
    "Y = tf.Variable(y_data)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random.normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random.normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "hypothesis = lambda: x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "# cost/loss function\n",
    "@tf.function\n",
    "def cost():\n",
    "    return tf.reduce_mean(tf.square(hypothesis() - Y))\n",
    "\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.optimizers.SGD(learning_rate=1e-5)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "\n",
    "for step in range(2001):\n",
    "    optimizer.minimize(cost, [w1, w2, w3, b])\n",
    "    cost_val = cost()\n",
    "    hy_val = hypothesis()\n",
    "    if step == 0 or step == 10 or step == 1990 or step == 2000:\n",
    "        tf.print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "\n",
    "'''\n",
    "0 Cost:  19614.8\n",
    "Prediction:\n",
    " [ 21.69748688  39.10213089  31.82624626  35.14236832  32.55316544]\n",
    "10 Cost:  14.0682\n",
    "Prediction:\n",
    " [ 145.56100464  187.94958496  178.50236511  194.86721802  146.08096313]\n",
    "\n",
    " ...\n",
    "\n",
    "1990 Cost:  4.9197\n",
    "Prediction:\n",
    " [ 148.15084839  186.88632202  179.6293335   195.81796265  144.46044922]\n",
    "2000 Cost:  4.89449\n",
    "Prediction:\n",
    " [ 148.15931702  186.8805542   179.63194275  195.81971741  144.45298767]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
