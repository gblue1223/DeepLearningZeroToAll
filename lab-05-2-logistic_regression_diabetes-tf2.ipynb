{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n",
      "Step:  0 cost:  1.0494523\n",
      "Step:  1000 cost:  0.730168581\n",
      "Step:  2000 cost:  0.641733587\n",
      "Step:  3000 cost:  0.586539924\n",
      "Step:  4000 cost:  0.55196172\n",
      "Step:  5000 cost:  0.529883564\n",
      "Step:  6000 cost:  0.515354\n",
      "Step:  7000 cost:  0.505454421\n",
      "Step:  8000 cost:  0.498479307\n",
      "Step:  9000 cost:  0.493414313\n",
      "Step:  10000 cost:  0.48963818\n",
      "\n",
      "Hypothesis:  [[0.463920891]\n",
      " [0.925328851]\n",
      " [0.258156657]\n",
      " ...\n",
      " [0.789822161]\n",
      " [0.730369866]\n",
      " [0.894775808]] \n",
      "Correct (Y):  [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]] \n",
      "Accuracy:  0.769433439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n0 0.82794\\n200 0.755181\\n400 0.726355\\n600 0.705179\\n800 0.686631\\n...\\n9600 0.492056\\n9800 0.491396\\n10000 0.490767\\n\\n...\\n\\n [ 1.]\\n [ 1.]\\n [ 1.]]\\nAccuracy:  0.762846\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "from functools import partial as bind\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "assert(tf.__version__.find('2') == 0)\n",
    "\n",
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "W = tf.Variable(tf.random.normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(-tf.matmul(X, W)))\n",
    "hypothesis = lambda X: tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost/loss function\n",
    "@tf.function\n",
    "def cost(X, Y):\n",
    "    return -tf.reduce_mean(Y * tf.math.log(hypothesis(X)) + (1 - Y) *\n",
    "                           tf.math.log(1 - hypothesis(X)))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# Launch graph\n",
    "for step in range(10001):\n",
    "    # Minimize\n",
    "    optimizer.minimize(bind(cost, x_data, y_data), var_list=[W, b])\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        # evaluate training accuracy\n",
    "        tf.print(\"Step: \", step, \"cost: \", bind(cost, x_data, y_data)())\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "h = hypothesis(x_data)\n",
    "predicted = tf.cast(h > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y_data), dtype=tf.float32))\n",
    "\n",
    "# Accuracy report\n",
    "tf.print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", predicted, \"\\nAccuracy: \", accuracy)\n",
    "\n",
    "'''\n",
    "0 0.82794\n",
    "200 0.755181\n",
    "400 0.726355\n",
    "600 0.705179\n",
    "800 0.686631\n",
    "...\n",
    "9600 0.492056\n",
    "9800 0.491396\n",
    "10000 0.490767\n",
    "\n",
    "...\n",
    "\n",
    " [ 1.]\n",
    " [ 1.]\n",
    " [ 1.]]\n",
    "Accuracy:  0.762846\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
